{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoUbbWfnnTQ"
      },
      "source": [
        "# 0. 초기 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LjVNJocZ2IR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Pytorch에서 gpu를 사용하는 방법.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FITNRngsETeP"
      },
      "outputs": [],
      "source": [
        "# torch ver 1.12.1\n",
        "# torchaudio ver 0.12.1\n",
        "# torchvision 0.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcspYaHHKoOq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr8LbbalETeT"
      },
      "outputs": [],
      "source": [
        "print(torch.version)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-KLMtHmhco7"
      },
      "source": [
        "# 1. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fGDVYPLN4vt"
      },
      "outputs": [],
      "source": [
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSifeRI5NZIR"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "import tifffile as tiff\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryQl2r-uETeY"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import segmentation_models as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0Ucurv9N9xj"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from keras.metrics import MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt_htC4wnOFZ"
      },
      "outputs": [],
      "source": [
        "# RLE 디코딩 함수\n",
        "def rle_decode(mask_rle, shape):\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape)\n",
        "\n",
        "\n",
        "# RLE 인코딩 함수\n",
        "def rle_encode(mask):\n",
        "    pixels = mask.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return \" \".join(str(x) for x in runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DXpo9QomS99"
      },
      "source": [
        "`1` Quick understanding of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIWesMLcmfax"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = pd.read_csv('./train.csv'), pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ems0XEPIETed"
      },
      "outputs": [],
      "source": [
        "'./data' + df_train.loc[0, 'img_path'][1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Kp_n4ghi4R"
      },
      "outputs": [],
      "source": [
        "temp_img = cv2.imread('./data' + df_train.loc[0, 'img_path'][1:]) #3 channels / spectral bands\n",
        "plt.imshow(temp_img[:,:,2]) #View each channel...\n",
        "temp_mask = rle_decode(df_train.loc[0, 'mask_rle'], shape = (1024, 1024)) #1 channels\n",
        "labels, count = np.unique(temp_mask[:, :], return_counts=True) #Check for each channel. All chanels are identical\n",
        "print(\"Labels are: \", labels, \" and the counts are: \", count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ebfl6anlx9"
      },
      "source": [
        "`2` Now, crop each large image into patches of 224x224. Save them into a directory\n",
        "\n",
        "so we can use data augmentation and read directly from the drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHd5J5qon4zY"
      },
      "outputs": [],
      "source": [
        "patch_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LOiBsh8sHBq"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df_train)):\n",
        "    img_path = './data' + df_train.loc[i, 'img_path'][1:]\n",
        "    image = cv2.imread(img_path)       #Read each image as BGR\n",
        "    SIZE_X = (image.shape[1] // patch_size) * patch_size  #Nearest size divisible by our patch size\n",
        "    SIZE_Y = (image.shape[0] // patch_size) * patch_size  #Nearest size divisible by our patch size\n",
        "    image = Image.fromarray(image)\n",
        "    image = image.crop((0 ,0, SIZE_X, SIZE_Y))\n",
        "    image = np.array(image)\n",
        "\n",
        "    #Extract patches from each image\n",
        "    print(\"Now patchifying image:\", img_path)\n",
        "    patches_img = patchify(image, (224, 224, 3), step=224)\n",
        "\n",
        "    for j in range(patches_img.shape[0]):\n",
        "        for k in range(patches_img.shape[1]):\n",
        "\n",
        "            single_patch_img = patches_img[j,k,:,:]\n",
        "            single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.\n",
        "\n",
        "            cv2.imwrite(\"./224_patches/images/\"+ df_train.loc[i, 'img_id'] + \"patch_\"+str(j)+str(k)+\".png\", single_patch_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y45hH2nioDT7"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df_train)):\n",
        "    mask = rle_decode(df_train.loc[i, 'mask_rle'], shape = (1024, 1024))\n",
        "    SIZE_X = (mask.shape[1] // patch_size) * patch_size  #Nearest size divisible by our patch size\n",
        "    SIZE_Y = (mask.shape[0] // patch_size) * patch_size  #Nearest size divisible by our patch size\n",
        "    mask = Image.fromarray(mask)\n",
        "    mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))\n",
        "    mask = np.array(mask)\n",
        "\n",
        "    #Extract patches from each image\n",
        "    print(\"Now patchifying mask:\", i)\n",
        "    patches_mask = patchify(mask, (224, 224), step=224)\n",
        "\n",
        "    for j in range(patches_mask.shape[0]):\n",
        "        for k in range(patches_mask.shape[1]):\n",
        "\n",
        "            single_patch_mask = patches_mask[j,k,:,:]\n",
        "\n",
        "            cv2.imwrite(\"./224_patches/masks/\"+ \"MASK_\" + df_train.loc[i, 'img_id'][-4:] + \"patch_\"+str(j)+str(k)+\".png\", single_patch_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GiIXUMBX4En"
      },
      "outputs": [],
      "source": [
        "image_test = cv2.imread(\"./224_patches/images/TRAIN_0000patch_01.png\", 1)\n",
        "image_test = cv2.cvtColor(image_test, cv2.COLOR_BGR2RGB)\n",
        "mask_test = cv2.imread(\"./224_patches/masks/MASK_0000patch_01.png\", 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkTFK0OHW5lX"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoZKkMWOoDMS"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mask_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4b8o6Q7mehs"
      },
      "outputs": [],
      "source": [
        "train_img_dir = \"224_patches/images/\"\n",
        "train_mask_dir = \"224_patches/masks/\"\n",
        "\n",
        "img_list = os.listdir(train_img_dir)\n",
        "msk_list = os.listdir(train_mask_dir)\n",
        "\n",
        "num_images = len(img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBZ-OO4Gc2O-"
      },
      "outputs": [],
      "source": [
        "print(len(img_list), len(msk_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVOMGPoUETeg"
      },
      "outputs": [],
      "source": [
        "img_list = sorted(img_list)\n",
        "msk_list = sorted(msk_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDiey88moDJr"
      },
      "outputs": [],
      "source": [
        "img_num = random.randint(0, num_images-1)\n",
        "\n",
        "img_for_plot = cv2.imread(train_img_dir + img_list[img_num], 1)\n",
        "img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_for_plot = cv2.imread(train_mask_dir + msk_list[img_num], 0)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_for_plot)\n",
        "plt.title('Image')\n",
        "plt.subplot(122)\n",
        "plt.imshow(mask_for_plot, cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttxUImamETeh"
      },
      "outputs": [],
      "source": [
        "img_list[img_num]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3R4UsBpETeh"
      },
      "outputs": [],
      "source": [
        "msk_list[img_num]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iulfslKoDDN"
      },
      "source": [
        "`3` Now, let us copy images and masks with real information to a new folder.\n",
        "real information = if mask has decent amount of labels other than 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YccnKcjToC8x"
      },
      "outputs": [],
      "source": [
        "useless=0  #Useless image counter\n",
        "for img in range(len(img_list)):   #Using t1_list as all lists are of same size\n",
        "    img_name=img_list[img]\n",
        "    mask_name = msk_list[img]\n",
        "    print(\"Now preparing image and masks number: \", img)\n",
        "\n",
        "    temp_image=cv2.imread(train_img_dir+img_list[img], 1)\n",
        "\n",
        "    temp_mask=cv2.imread(train_mask_dir+msk_list[img], 0)\n",
        "    #temp_mask=temp_mask.astype(np.uint8)\n",
        "\n",
        "    val, counts = np.unique(temp_mask, return_counts=True)\n",
        "\n",
        "    if (1 - (counts[0]/counts.sum())) > 0.05:  #At least 5% useful area with labels that are not 0\n",
        "        print(\"Save Me\")\n",
        "        cv2.imwrite('./224_patches/images_with_useful_info/images/' + img_name, temp_image)\n",
        "        cv2.imwrite('./224_patches/images_with_useful_info/masks/' + mask_name, temp_mask)\n",
        "\n",
        "    else:\n",
        "        print(\"I am useless\")\n",
        "        useless +=1\n",
        "\n",
        "print(\"Total useful images are: \", len(img_list)-useless)  #48,843\n",
        "print(\"Total useless images are: \", useless) #65,397"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jNRQ_G2ETei"
      },
      "outputs": [],
      "source": [
        "useful_train_img_dir = './224_patches/images_with_useful_info/images/'\n",
        "useful_train_mask_dir = './224_patches/images_with_useful_info/masks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agIhT0OloC1C"
      },
      "outputs": [],
      "source": [
        "useful_img_list = os.listdir(useful_train_img_dir)\n",
        "useful_msk_list = os.listdir(useful_train_mask_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBJcfMB-ETej"
      },
      "outputs": [],
      "source": [
        "useful_img_list = sorted(useful_img_list)\n",
        "useful_msk_list = sorted(useful_msk_list)\n",
        "useful_num_images = len(useful_img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrQeo9EAETej"
      },
      "outputs": [],
      "source": [
        "img_num = random.randint(0, useful_num_images-1)\n",
        "\n",
        "img_for_plot = cv2.imread(useful_train_img_dir + useful_img_list[img_num], 1)\n",
        "img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_for_plot = cv2.imread(useful_train_mask_dir + useful_msk_list[img_num], 0)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_for_plot)\n",
        "plt.title('Image')\n",
        "plt.subplot(122)\n",
        "plt.imshow(mask_for_plot, cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj066xP6ETej"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_train, img_test, mask_train, mask_test = train_test_split(useful_img_list, useful_msk_list, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUZJKdBaETek"
      },
      "outputs": [],
      "source": [
        "train_set = pd.DataFrame({'img_path': img_train, 'mask_path': mask_train})\n",
        "valid_set = pd.DataFrame({'img_path': img_test, 'mask_path': mask_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cmKBFY0ETek"
      },
      "outputs": [],
      "source": [
        "valid_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNOyCIEzETek"
      },
      "outputs": [],
      "source": [
        "test_set = pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSfpzd7_ETel"
      },
      "outputs": [],
      "source": [
        "test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4` split folders"
      ],
      "metadata": {
        "id": "-q8tIieUE4YG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-yYdBGlETel"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOVkaye8ETem"
      },
      "outputs": [],
      "source": [
        "import splitfolders  # or import split_folders\n",
        "\n",
        "input_folder = './224_patches/images_with_useful_info/'\n",
        "output_folder = './pro_data/data_for_training_and_testing/'\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None) # default values"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}